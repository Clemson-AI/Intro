{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_Deep_Learning_CAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WnbFJSFW0kW"
      },
      "source": [
        "# Intro to Deep Learning\r\n",
        "<table align=\"left\"><td>\r\n",
        "  <a target=\"_blank\"  href=\"https://github.com/Clemson-AI/Intro/blob/master/Intro_to_Deep_Learning_CAI.ipynb\">\r\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\r\n",
        "  </a>\r\n",
        "</td><td>\r\n",
        "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/Clemson-AI/Intro/blob/master/Intro_to_Deep_Learning_CAI.ipynb\">\r\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\r\n",
        "</td></table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbslkSc-J_Pq"
      },
      "source": [
        "import torch\r\n",
        "import torchvision.models as models\r\n",
        "from torchvision import transforms as T\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import numpy as np\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from google.colab import files"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0nOdrvQ8KO"
      },
      "source": [
        "# Tensors\r\n",
        "![Tensor](https://miro.medium.com/max/1050/0*jGB1CGQ9HdeUwlgB)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMEdL5BcMCcu"
      },
      "source": [
        "# Rank 0\r\n",
        "torch.tensor(.6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjaxmMrZg7GH"
      },
      "source": [
        "# Rank 1 \r\n",
        "torch.tensor([.7, 1.4, 2.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywMGcKEck1ZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53a9b8a5-e236-4e2a-d410-fc68b21ce752"
      },
      "source": [
        "# Rank 2\r\n",
        "torch.randn(2,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.5733, -0.4501],\n",
              "        [ 0.7236,  0.9845]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VUXHhi7gr7W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92556f77-00d3-4557-9475-3294f88bbb90"
      },
      "source": [
        "# Rank 4\r\n",
        "torch.randn(2,2,2,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-0.3028, -0.4098],\n",
              "          [ 0.4015,  0.2455]],\n",
              "\n",
              "         [[ 1.6076,  0.5838],\n",
              "          [ 0.6200, -0.6811]]],\n",
              "\n",
              "\n",
              "        [[[ 0.3436,  1.0570],\n",
              "          [ 0.3909,  1.9183]],\n",
              "\n",
              "         [[ 0.3407,  0.4702],\n",
              "          [-0.7572, -0.5975]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BspdStnjsFE-"
      },
      "source": [
        "# Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uR3r-VMsImA"
      },
      "source": [
        "t1 = torch.tensor([5.0, 6.0])\r\n",
        "t2 = torch.tensor([[5.0, 6.0], [6.0, 5.0], [.2, .7]])\r\n",
        "t3 = torch.tensor([])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ACzi0RsaJ2",
        "outputId": "493c7d53-ec96-46d0-b9cd-06741e6e4c5f"
      },
      "source": [
        "result = t1 * t2"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[25.0000, 36.0000],\n",
              "        [30.0000, 30.0000],\n",
              "        [ 1.0000,  4.2000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdG6SkJouFaz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqG8ejNTNhhB"
      },
      "source": [
        "# Activation Function\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "\r\n",
        "Sigmoid(x) = \\sigma(x) = \\dfrac{1}{1 + \\exp(-x)}\r\n",
        "\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "â€‹\t\r\n",
        "![Sigmoid](https://pytorch.org/docs/stable/_images/Sigmoid.png)\r\n",
        "\\begin{equation}\r\n",
        "ReLU(x) = x^+ = max(0,x)\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "![ReLu](https://pytorch.org/docs/stable/_images/ReLU.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRQ-qZ8Xh7RD"
      },
      "source": [
        "Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaEmf3R5hnC5"
      },
      "source": [
        "# Rank 0\r\n",
        "r0data = torch.tensor(.6)\r\n",
        "# Rank 1 \r\n",
        "r1data = torch.tensor([.7, 1.4, 2.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gbVZhbcKBi8"
      },
      "source": [
        "sig = nn.Sigmoid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Kide_RLUsC",
        "outputId": "0b53b25f-27de-4619-a4e5-72353c53c972"
      },
      "source": [
        "sig(r0data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.6457)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6kz8O9bcwrY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56097b85-79ed-4ad8-cce7-c22f20bfd368"
      },
      "source": [
        "sig(r1data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6682, 0.8022, 0.8909])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OhYV5a8hadj"
      },
      "source": [
        "ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eF-I2HoTHG8"
      },
      "source": [
        "relu = nn.ReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDMRDe_uc823",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed7d1039-158d-4c20-c817-1df8b21633a1"
      },
      "source": [
        "relu(r1data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7000, 1.4000, 2.1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnMTKm22TJ7t",
        "outputId": "fbd7281b-3821-4b14-d9ec-7c33db1b4bc0"
      },
      "source": [
        "relu(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DQoj-ep2a7d"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTr_G8Sr2aeN"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        # 1 input image channel, 6 output channels, 3x3 square convolution\r\n",
        "        # kernel\r\n",
        "        self.conv1 = nn.Conv2d(1, 6, 3)\r\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\r\n",
        "        # an affine operation: y = Wx + b\r\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)  # 6*6 from image dimension \r\n",
        "        self.fc2 = nn.Linear(120, 84)\r\n",
        "        self.fc3 = nn.Linear(84, 10)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        # Max pooling over a (2, 2) window\r\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\r\n",
        "        # If the size is a square you can only specify a single number\r\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\r\n",
        "        x = x.view(-1, self.num_flat_features(x))\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.relu(self.fc2(x))\r\n",
        "        x = self.fc3(x)\r\n",
        "        return x\r\n",
        "\r\n",
        "    def num_flat_features(self, x):\r\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\r\n",
        "        num_features = 1\r\n",
        "        for s in size:\r\n",
        "            num_features *= s\r\n",
        "        return num_features\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsSJvhUQRg3e"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB2Gjifz8CPa"
      },
      "source": [
        "### <center>L1Loss</center>\r\n",
        "\\begin{equation}\r\n",
        "loss = \\dfrac{\\sum_{i=1}^{n}âˆ£y_iâˆ’x_iâˆ£}{n}\r\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPWGYtscvnLZ"
      },
      "source": [
        "### <center>Binary Cross Entropy Loss</center>\r\n",
        "<p align=\"center\">\r\n",
        "  <img src=\"https://miro.medium.com/max/1096/1*rdBw0E-My8Gu3f_BOB6GMA.png\" />\r\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hOF6tllVMxY"
      },
      "source": [
        "data = torch.tensor([5.0,5.0,5.0])\r\n",
        "truth = torch.tensor([7.0,8.0,9.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0lzLs7MVxKJ"
      },
      "source": [
        "# L1 Loss, mean absolute error (MAE) useful for Regression tasks\r\n",
        "loss = nn.L1Loss(reduction='mean')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iM8MonBR-TF",
        "outputId": "6b441e7a-e8cd-444a-ec6d-9e2b62801527"
      },
      "source": [
        "loss(data, truth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzsWRU-7xjr1"
      },
      "source": [
        "# BCELoss is useful for Classification tasks\r\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqypwK-AhxCl"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGx5QeZRhz42"
      },
      "source": [
        "optimizer = optim.SGD(net.parameters(), lr=0.01)\r\n",
        "\r\n",
        "# in your training loop:\r\n",
        "optimizer.zero_grad()   # zero the gradient buffers\r\n",
        "output = net(input)\r\n",
        "loss = criterion(output, target)\r\n",
        "loss.backward()\r\n",
        "optimizer.step()    # Does the update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ort_UN7uduFC"
      },
      "source": [
        "# Transfer Learning with VGG Backbone\r\n",
        "[Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiFVc2RadwwV"
      },
      "source": [
        "# vgg16 is a Convolutional Neural Network(CNN) trained on Imagenet 2014 - 1000 categories and 1.2 million images\r\n",
        "vgg16 = models.vgg16(pretrained=True)\r\n",
        "\r\n",
        "# Turn off training for vgg16\r\n",
        "for param in vgg16.parameters():\r\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gof-F4vedyf6"
      },
      "source": [
        "vgg16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHVnLogi9wYV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MhO3li9xdy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1DPWK6r937S"
      },
      "source": [
        "# Saving and Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmLblABp96TQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_emswkN9yDo"
      },
      "source": [
        "# Action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blz13mUX91bz"
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}