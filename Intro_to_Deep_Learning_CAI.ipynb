{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro_to_Deep_Learning_CAI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WnbFJSFW0kW"
      },
      "source": [
        "# Intro to Deep Learning\r\n",
        "<table align=\"left\"><td>\r\n",
        "  <a target=\"_blank\"  href=\"https://github.com/Clemson-AI/Intro/blob/master/Intro_to_Deep_Learning_CAI.ipynb\">\r\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on github\r\n",
        "  </a>\r\n",
        "</td><td>\r\n",
        "  <a target=\"_blank\"  href=\"https://colab.sandbox.google.com/github/Clemson-AI/Intro/blob/master/Intro_to_Deep_Learning_CAI.ipynb\">\r\n",
        "    <img width=32px src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\r\n",
        "</td></table>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbslkSc-J_Pq"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import numpy as np\r\n",
        "import os, json, cv2, random\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_0nOdrvQ8KO"
      },
      "source": [
        "# Pytorch Tensors\r\n",
        "<img src=\"https://miro.medium.com/max/1050/0*jGB1CGQ9HdeUwlgB\" width=70% height=70% alt=\"Tensor\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjaxmMrZg7GH"
      },
      "source": [
        "# Rank 1 \r\n",
        "torch.tensor([.7, 1.4, 2.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywMGcKEck1ZU"
      },
      "source": [
        "# Rank 2\r\n",
        "torch.randn(2,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VUXHhi7gr7W"
      },
      "source": [
        "# Rank 4\r\n",
        "torch.randn(2,2,2,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BspdStnjsFE-"
      },
      "source": [
        "# Matrix Multiplication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uR3r-VMsImA"
      },
      "source": [
        "t1 = torch.tensor([1.0, 2.0, 3.0])\r\n",
        "t2 = torch.tensor([[.3, .2], [.5, .5], [.2, .2]])\r\n",
        "t3 = torch.tensor([])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KbTHQZUr6Dl"
      },
      "source": [
        "result = t1.matmul(t2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iv88Xl3kWHk"
      },
      "source": [
        "result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqG8ejNTNhhB"
      },
      "source": [
        "# Defining Activation Functions\r\n",
        "\r\n",
        "\\begin{equation}\r\n",
        "\r\n",
        "Sigmoid(x) = \\sigma(x) = \\dfrac{1}{1 + \\exp(-x)}\r\n",
        "\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "![Sigmoid](https://pytorch.org/docs/stable/_images/Sigmoid.png)\r\n",
        "\\begin{equation}\r\n",
        "\r\n",
        "ReLU(x) = x^+ = max(0,x)\r\n",
        "\\end{equation}\r\n",
        "\r\n",
        "![ReLu](https://pytorch.org/docs/stable/_images/ReLU.png)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRQ-qZ8Xh7RD"
      },
      "source": [
        "Sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4d3AGnAmggR"
      },
      "source": [
        "# Define non linearity\r\n",
        "sigmoid = nn.Sigmoid()\r\n",
        "relu = nn.ReLU()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4Kide_RLUsC"
      },
      "source": [
        "# Take the sigmoid of our example\r\n",
        "test = sigmoid(result).matmul(torch.tensor([.4, .7]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwgKgu14wMWW"
      },
      "source": [
        "sigmoid(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OhYV5a8hadj"
      },
      "source": [
        "ReLU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDMRDe_uc823"
      },
      "source": [
        "# Rectified Linear Unit (ReLU)\r\n",
        "relu(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsSJvhUQRg3e"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jB2Gjifz8CPa"
      },
      "source": [
        "### <center>L1Loss</center>\r\n",
        "\\begin{equation}\r\n",
        "loss = \\dfrac{\\sum_{i=1}^{n}∣y_i−\\hat{y}_i∣}{n}\r\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPWGYtscvnLZ"
      },
      "source": [
        "### <center>Binary Cross Entropy Loss</center>\r\n",
        "<p align=\"center\">\r\n",
        "  <img src=\"https://miro.medium.com/max/1096/1*rdBw0E-My8Gu3f_BOB6GMA.png\" />\r\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPBWcttnnMGx"
      },
      "source": [
        "### Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hOF6tllVMxY"
      },
      "source": [
        "data = torch.tensor([5.0,5.0,5.0])\r\n",
        "truth = torch.tensor([7.0,8.0,9.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0lzLs7MVxKJ"
      },
      "source": [
        "# L1 Loss, mean absolute error (MAE) useful for Regression tasks\r\n",
        "criterion = nn.L1Loss(reduction='mean')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iM8MonBR-TF"
      },
      "source": [
        "criterion(data, truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEQEylH2nOd1"
      },
      "source": [
        "### Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahFLs0CmnQ2d"
      },
      "source": [
        "data = torch.tensor([.34, .25, 1.0])\r\n",
        "truth = torch.tensor([1.0, 0.0, 1.0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzsWRU-7xjr1"
      },
      "source": [
        "# BCELoss is useful for Classification tasks\r\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEn5_OBsm_B-"
      },
      "source": [
        "criterion(data, truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0a85ZSfIBExU"
      },
      "source": [
        "# Linear Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3c5UUKeezXO"
      },
      "source": [
        "# Remember our inputs and weight\r\n",
        "print(\"input: {}\\nweight: {}\".format(t1, t2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3eVhd7Rbv1K"
      },
      "source": [
        "# Perceptrons are called Linear Layers in Pytorch. \r\n",
        "# For example, this will take 3 inputs and output 2\r\n",
        "example = nn.Linear(3, 2, bias=False)\r\n",
        "\r\n",
        "# Setting weights as in presentation\r\n",
        "example.weight = nn.Parameter(t2, requires_grad=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI_K2PXLdbRw"
      },
      "source": [
        "example.weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NvsXECGcNh9"
      },
      "source": [
        "# Forward Pass\r\n",
        "example(t1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KTPb5uTfnXg"
      },
      "source": [
        "# Define A Neural Network\r\n",
        "To define a network in Pytorch, we can extend nn.Module. To use functions without defining them, we can use nn.functional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfhE1WQrBImJ"
      },
      "source": [
        "import torch.nn.functional as F\r\n",
        "IMG_SIZE = 150528\r\n",
        "class Model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        # Define your layers here\r\n",
        "        self.fc1 = nn.Linear(in_features=IMG_SIZE, out_features=, bias=)\r\n",
        "        self.fc2 = nn.Linear(1, 1) # bias defaults to True if you do not set it\r\n",
        "        #define more here\r\n",
        "\r\n",
        "        #define dropout\r\n",
        "        self.dropout = nn.Dropout(p=.5)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ### Do not change this\r\n",
        "        x = x.view(-1, 3*224*224)\r\n",
        "        ###\r\n",
        "        x = self.fc1(x) # Pass through first layer\r\n",
        "        x = F.relu(x) # Apply non-linearity\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = F.relu(self.fc2(x)) # you can also combine them like this\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = F.relu(self.fc3(x))\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = self.fc4(x)\r\n",
        "        return torch.sigmoid(x).squeeze() # Use sigmoid on final output, we want our results 0-1 (cat to dog)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Oztm40lHzk"
      },
      "source": [
        "# Create an instance of your defined model\r\n",
        "my_model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqypwK-AhxCl"
      },
      "source": [
        "# Optimizer\r\n",
        "To define an optimizer we have to import torch.optim:\r\n",
        "https://pytorch.org/docs/stable/optim.html  \r\n",
        "* [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)\r\n",
        "* [An overview of gradient descent optimization algorithms∗](https://arxiv.org/pdf/1609.04747.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGx5QeZRhz42"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "# Define your Optimizer or choose one, also choose a learning rate \r\n",
        "#optimizer = optim.SGD(my_model.parameters(), lr=0.01) \r\n",
        "#optimizer = optim.Adam(Model.parameters(), lr=0.01)\r\n",
        "\r\n",
        "# Use BCELoss for Binary Classification\r\n",
        "criterion = nn.BCELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJDo9V5NCOOZ"
      },
      "source": [
        "# Dataset\r\n",
        "Data processing is important, but we'll implement this part for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9aiSaDxCQQx"
      },
      "source": [
        "!curl -O https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd51Vy_vC8U6"
      },
      "source": [
        "!unzip -q kagglecatsanddogs_3367a.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-USUokPcmDpO"
      },
      "source": [
        "from PIL import Image \r\n",
        "def check_image(path):\r\n",
        "    try:\r\n",
        "        im = Image.open(path)\r\n",
        "        return True\r\n",
        "    except:\r\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YVqWPYpmEdb"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "for folder_name in (\"Cat\", \"Dog\"):\r\n",
        "    folder_path = os.path.join(\"PetImages\", folder_name)\r\n",
        "    for fname in os.listdir(folder_path):\r\n",
        "        fpath = os.path.join(folder_path, fname)\r\n",
        "        check = check_image(fpath)\r\n",
        "\r\n",
        "        if not check:\r\n",
        "            # Delete corrupted image\r\n",
        "            os.remove(fpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gth0oCP3nmng"
      },
      "source": [
        "len(data.samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1TkeXjHmkrO"
      },
      "source": [
        "from torchvision import datasets\r\n",
        "import torchvision.transforms as T\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torch.utils.data import random_split\r\n",
        "\r\n",
        "batch_size = 96\r\n",
        "\r\n",
        "transform = T.Compose([T.RandomHorizontalFlip(),\r\n",
        "                       T.Resize((224,224)),\r\n",
        "                       T.ToTensor(),\r\n",
        "                       T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\r\n",
        "                       ])\r\n",
        "\r\n",
        "\r\n",
        "data = datasets.ImageFolder(\"PetImages\", transform=transform)\r\n",
        "\r\n",
        "train_data, test_data = random_split(data, [20000, 4998])\r\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\r\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHVnLogi9wYV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6MhO3li9xdy"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\r\n",
        "if use_cuda:\r\n",
        "  my_model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AP8M0po7yadF"
      },
      "source": [
        "from math import ceil\r\n",
        "\r\n",
        "NUM_BATCH = ceil(19998/96)\r\n",
        "NUM_EPOCH = 2\r\n",
        "\r\n",
        "for i in range(NUM_EPOCH):\r\n",
        "  my_model.train()\r\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\r\n",
        "            # move to GPU\r\n",
        "            train_loss = 0.0\r\n",
        "            target = target.type(torch.FloatTensor)\r\n",
        "            if use_cuda:\r\n",
        "               data, target = data.cuda(), target.cuda()\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = my_model(data)\r\n",
        "            loss = criterion(output, target)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            train_loss += loss.item()\r\n",
        "\r\n",
        "            print('Epoch: {} {}/{}\\tTraining Loss: {:.6f}'.format(\r\n",
        "            i, \r\n",
        "            batch_idx,\r\n",
        "            NUM_BATCH,\r\n",
        "            train_loss\r\n",
        "            ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eBLd4X0AyEMl"
      },
      "source": [
        "# Test Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRFdW6gWyDBV"
      },
      "source": [
        "from math import ceil\r\n",
        "t_model.eval()\r\n",
        "NUM_BATCH = ceil(4998/96)\r\n",
        "\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\r\n",
        "      # move to GPU\r\n",
        "      target = target.type(torch.FloatTensor)\r\n",
        "      if use_cuda:\r\n",
        "          my_model.cuda()\r\n",
        "          vgg16.cuda()\r\n",
        "          data, target = data.cuda(), target.cuda()\r\n",
        "      output = my_model(data)\r\n",
        "      total += len(output)\r\n",
        "      for ypred, y in zip(output, target):\r\n",
        "        if round(ypred.item()) == round(y.item()): \r\n",
        "          correct += 1\r\n",
        "          \r\n",
        "\r\n",
        "      print('{}/{}\\t Correct: {}/{}'.format(\r\n",
        "        batch_idx,\r\n",
        "        NUM_BATCH,\r\n",
        "        correct,\r\n",
        "        total\r\n",
        "        ))\r\n",
        "print(\"Accuracy: {:.2%}\".format(correct/total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn9PL0Nf0fRd"
      },
      "source": [
        "Well done on training a MLP!  \r\n",
        "I got an accuracy of **60.86%** lmk if you beat this!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1DPWK6r937S"
      },
      "source": [
        "# Saving and Loading\r\n",
        "If you like your model, save it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZbnZF-Zgrx_"
      },
      "source": [
        "torch.save(my_model, \"my_model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QRqzOfi1SRI"
      },
      "source": [
        "# You can attach your Google Drive to copy the saved model\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KN_iUVid1d7A"
      },
      "source": [
        "!cp my_model.pt /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhHy8cv22CEV"
      },
      "source": [
        "model = torch.load(\"my_model.pt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ort_UN7uduFC"
      },
      "source": [
        "# Transfer Learning with VGG Backbone\r\n",
        "For a more powerful model, we can use a CNN backbone. VGG-16 is a CNN. CNNs are commonly used to extract features from images. Pytorch lets us import some pretrained models from torchvision.models.  \r\n",
        "\r\n",
        "* [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiFVc2RadwwV"
      },
      "source": [
        "import torchvision.models as models\r\n",
        "# vgg16 is a Convolutional Neural Network(CNN) trained on Imagenet 2014 - 1000 categories and 1.3 million images\r\n",
        "vgg16 = models.vgg16(pretrained=True)\r\n",
        "\r\n",
        "# Turn off training for vgg16\r\n",
        "for param in vgg16.parameters():\r\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gof-F4vedyf6"
      },
      "source": [
        "# We are going to reimplement the classifier layer for our task\r\n",
        "# For reference, this is the original\r\n",
        "vgg16.classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2AQfsXtT2G1"
      },
      "source": [
        "# Transfer Learning Explained\r\n",
        "Using a pretrained VGG backbone will dramatically increase our model accuracy. If you are curious about why transfer learning works, I've attached a video by Andrew Ng. He is the founder of coursera and [deeplearning.ai](https://deeplearning.ai). You can check them out for more content and subscribe to his weekly AI newsletter, The Batch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RndzTmC8TcfQ"
      },
      "source": [
        "# Embed youtube video \r\n",
        "from IPython.display import YouTubeVideo, display\r\n",
        "video = YouTubeVideo(\"yofjFQddwHE\", width=500)\r\n",
        "display(video)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFOY3hR-Yrka"
      },
      "source": [
        "# Defining a Classification Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk_nfaIxYvp8"
      },
      "source": [
        "VGG_OUT_FEATURES = vgg16.classifier[0].in_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAG8w-K0YwS5"
      },
      "source": [
        "import torch.nn.functional as F\r\n",
        "class Model(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Model, self).__init__()\r\n",
        "        # Define your layers here\r\n",
        "        self.fc1 = nn.Linear(in_features=VGG_OUT_FEATURES, out_features=)\r\n",
        "        self.fc2 = nn.Linear(1 ,1)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        ### Do not change this section\r\n",
        "        x = vgg16.features(x)\r\n",
        "        x = vgg16.avgpool(x)\r\n",
        "        x = x.view(-1, 7*7*512)\r\n",
        "        ###\r\n",
        "\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = \r\n",
        "\r\n",
        "        return torch.sigmoid(x).squeeze()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTEfK3j18K8"
      },
      "source": [
        "t_model = Model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-pEBddCzxrK"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q01RFE-ohs_x"
      },
      "source": [
        "use_cuda = torch.cuda.is_available()\r\n",
        "if use_cuda:\r\n",
        "  t_model.cuda()\r\n",
        "  vgg16.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQDwsDaPhWkr"
      },
      "source": [
        "import torch.optim as optim\r\n",
        "criterion = nn.BCELoss()\r\n",
        "optimizer = optim.Adam(t_model.parameters(), lr=0.001)\r\n",
        "NUM_EPOCH = 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoYiKK-Szv_4"
      },
      "source": [
        "from math import ceil\r\n",
        "NUM_BATCH = ceil(19998/96)\r\n",
        "for i in range(NUM_EPOCH):\r\n",
        "  t_model.train()\r\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\r\n",
        "            # move to GPU\r\n",
        "            train_loss = 0.0\r\n",
        "            target = target.type(torch.FloatTensor)\r\n",
        "            if use_cuda:\r\n",
        "               data, target = data.cuda(), target.cuda()\r\n",
        "\r\n",
        "            optimizer.zero_grad()\r\n",
        "            output = t_model(data)\r\n",
        "            loss = criterion(output, target)\r\n",
        "            loss.backward()\r\n",
        "            optimizer.step()\r\n",
        "            train_loss += loss.item()\r\n",
        "\r\n",
        "            print('Epoch: {} {}/{}\\tTraining Loss: {:.6f}'.format(\r\n",
        "            i, \r\n",
        "            batch_idx,\r\n",
        "            NUM_BATCH,\r\n",
        "            train_loss\r\n",
        "            ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_emswkN9yDo"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdV5i-jspetN"
      },
      "source": [
        "# Let's see how it does on the test dataset\r\n",
        "from math import ceil\r\n",
        "t_model.eval()\r\n",
        "NUM_BATCH = ceil(4998/96)\r\n",
        "\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "for batch_idx, (data, target) in enumerate(test_loader):\r\n",
        "      # move to GPU\r\n",
        "      target = target.type(torch.FloatTensor)\r\n",
        "      if use_cuda:\r\n",
        "          t_model.cuda()\r\n",
        "          vgg16.cuda()\r\n",
        "          data, target = data.cuda(), target.cuda()\r\n",
        "      output = t_model(data)\r\n",
        "      total += len(output)\r\n",
        "      for ypred, y in zip(output, target):\r\n",
        "        if round(ypred.item()) == round(y.item()): \r\n",
        "          correct += 1\r\n",
        "          \r\n",
        "\r\n",
        "      print('{}/{}\\t Correct: {}/{}'.format(\r\n",
        "        batch_idx,\r\n",
        "        NUM_BATCH,\r\n",
        "        correct,\r\n",
        "        total\r\n",
        "        ))\r\n",
        "print(\"Accuracy: {:.2%}\".format(correct/total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aFUIfTMpa2_"
      },
      "source": [
        "# Don't need gpu for one image\r\n",
        "t_model.cpu()\r\n",
        "vgg16.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPESMhvbvrLd"
      },
      "source": [
        "from PIL import Image \r\n",
        "def process(im_path):  \r\n",
        "  im = Image.open(im_path)\r\n",
        "  return transform(im)[:3,:,:].unsqueeze(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blz13mUX91bz"
      },
      "source": [
        "# Upload your own image\r\n",
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nkOBZWjEzlQ"
      },
      "source": [
        "# Process Image\r\n",
        "img = process(\"download.jpg\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xou4B9DUE2EA"
      },
      "source": [
        "# Cats were labeled 0 and Dogs 1\r\n",
        "key = {\r\n",
        "    0 : \"Cat\",\r\n",
        "    1 : \"Dog\"\r\n",
        "}\r\n",
        "prediction = t_model(im)\r\n",
        "\r\n",
        "# Show your image\r\n",
        "im = cv2.imread(\"download.jpg\")\r\n",
        "cv2_imshow(im)\r\n",
        "\r\n",
        "print(key[round(prediction.item())], \"{:.2%}\".format(abs((prediction.item()-.5)*2)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}